{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of CS5242_Group22_Kaggle.ipynb","provenance":[{"file_id":"1Zow2ZvpCI39InAvRY5jZ3lLVel6pJLR2","timestamp":1573911685266}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"NbLNQOPyBEyy","colab_type":"text"},"source":["# Import Packages"]},{"cell_type":"code","metadata":{"id":"TZKTM4Si_PVH","colab_type":"code","colab":{}},"source":["import pandas as pd\n","import numpy as np\n","from os import listdir\n","import matplotlib.pyplot as plt\n","from datetime import datetime\n","from pytz import timezone\n","\n","# import tensorflow as tf\n","from keras import metrics\n","from keras.optimizers import Adam, SGD\n","from keras.models import Sequential, load_model, Model\n","from keras import backend\n","from keras.layers import GRU, Conv1D, Dense, AveragePooling1D, MaxPooling1D, Dropout, Input, concatenate, LSTM, Bidirectional\n","from keras.callbacks import EarlyStopping, Callback, LearningRateScheduler, TensorBoard, ReduceLROnPlateau, ModelCheckpoint, History\n","from keras import regularizers"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4lL71MZZBIFo","colab_type":"text"},"source":["# Data loading"]},{"cell_type":"code","metadata":{"id":"rWObZsaVBL0L","colab_type":"code","colab":{}},"source":["# read all training sequence for all instances\n","path = '/content/kaggle/train/'\n","sequences = list()\n","\n","for i in range(0, len(listdir(path))):\n","    file_name = path + str(i) + '.npy'\n","    data = np.load(file_name)\n","    df = pd.DataFrame(data=data[:,:], index=None, columns=None)\n","    df = df.drop(df.iloc[:,64:92].head(0).columns, axis=1)\n","    values = df.values\n","    sequences.append(values)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lm3sFp3_BcFf","colab_type":"code","colab":{}},"source":["# padding the sequence with values from last row for each sequence\n","# since most of the sequence are 1000 length, no need to truncate further after padding\n","\n","to_pad = 1000\n","new_sequences = []\n","for seq in sequences:\n","    len_seq = len(seq)\n","    # last_val = seq[-1]\n","    last_val = [0]*74\n","    n = to_pad - len_seq\n","    '''\n","    to_concat = np.repeat(seq[-1], n).reshape(102, n).transpose()\n","    new_seq = np.concatenate([seq, to_concat])\n","    new_sequences.append(new_seq)\n","    '''\n","    to_concat = np.repeat(last_val, n).reshape(74, n).transpose()\n","    new_seq = np.concatenate([seq, to_concat])\n","    new_sequences.append(new_seq)\n","    \n","final_seq = np.stack(new_sequences)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mn4x2CsUBMK2","colab_type":"text"},"source":["# Data Splitting and Model Training"]},{"cell_type":"code","metadata":{"id":"s_2uLF58BlJT","colab_type":"code","colab":{}},"source":["# split the data into training, test, validation\n","from sklearn.model_selection import train_test_split, StratifiedKFold\n","\n","#k fold CV\n","k=10\n","folds = list(StratifiedKFold(n_splits=k, shuffle=True, random_state=None).split(final_seq, target))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oF9FQqTUBpOq","colab_type":"text"},"source":["## Model 1 - Two Convolutions fed into one GRU layer"]},{"cell_type":"code","metadata":{"id":"caamSMhqBq2t","colab_type":"code","colab":{}},"source":["model_id = 1\n","\n","backend.clear_session()\n","\n","#input layer\n","visible = Input(shape=(1000,74))\n","\n","#2 separate convolution1 layers\n","left_conv1 = Conv1D(256, kernel_size=4, strides=2, padding='same')(visible)\n","right_conv1 = Conv1D(256, kernel_size=4, strides=2, padding='same', activation='sigmoid')(visible)\n","merge = concatenate([left_conv1, right_conv1])\n","gru = GRU(128, dropout=0.3, recurrent_dropout=0.3, \n","          activation=\"sigmoid\",recurrent_activation=\"sigmoid\")(merge)\n","          # activity_regularizer=regularizers.l1(0.01))(merge)\n","output = Dense(1, activation='sigmoid')(gru)\n","model = Model(inputs=[visible], outputs=output)\n","\n","model.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dkB-wEifBvqh","colab_type":"text"},"source":["## Model 2 - Two Convolutions fed into two GRU layer"]},{"cell_type":"code","metadata":{"id":"_P965yqzBxwJ","colab_type":"code","colab":{}},"source":["model_id = 2\n","\n","backend.clear_session()\n","\n","#input layer\n","visible = Input(shape=(1000,74))\n","\n","#2 separate convolution1 layers\n","left_conv1 = Conv1D(128, kernel_size=4, strides=2, padding='same')(visible)\n","right_conv1 = Conv1D(128, kernel_size=4, strides=2, padding='same', activation='sigmoid')(visible)\n","merge = concatenate([left_conv1, right_conv1])\n","gru = GRU(64, dropout=0.3, recurrent_dropout=0.3, activation=\"sigmoid\",recurrent_activation=\"sigmoid\", return_sequences=True)(merge)\n","gru2 = GRU(64, dropout=0.3, recurrent_dropout=0.3, activation=\"sigmoid\",recurrent_activation=\"sigmoid\")(gru)\n","output = Dense(1, activation='sigmoid')(gru2)\n","model = Model(inputs=[visible], outputs=output)\n","\n","model.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"537weQ-HB87O","colab_type":"text"},"source":["## Model 3 - Two Convolutions fed into one Birdirectional GRU layer"]},{"cell_type":"code","metadata":{"id":"iAbmK50OB-oX","colab_type":"code","colab":{}},"source":["model_id = 3\n","\n","backend.clear_session()\n","\n","#input layer\n","visible = Input(shape=(1000,74))\n","\n","#2 separate convolution1 layers\n","left_conv1 = Conv1D(256, kernel_size=4, strides=2, padding='same')(visible)\n","right_conv1 = Conv1D(256, kernel_size=4, strides=2, padding='same', activation='sigmoid')(visible)\n","merge = concatenate([left_conv1, right_conv1])\n","gru = Bidirectional(GRU(128, dropout=0.3, recurrent_dropout=0.3, \n","          activation=\"sigmoid\",recurrent_activation=\"sigmoid\"))(merge)\n","          # activity_regularizer=regularizers.l1(0.01)))(merge)\n","output = Dense(1, activation='sigmoid')(gru)\n","model = Model(inputs=[visible], outputs=output)\n","\n","model.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RhTHnuOim_Xg","colab_type":"code","colab":{}},"source":["# split the data into training, test, validation\n","from sklearn.model_selection import train_test_split\n","\n","X_train, X_valid, y_train, y_valid = train_test_split(final_seq, target, test_size=0.1, random_state=1)\n","\n","X_train = np.array(X_train)\n","y_train = np.array(y_train)\n","X_valid = np.array(X_valid)\n","y_valid = np.array(y_valid)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"XNScXsTYdMVp"},"source":["## Model 4 - 8"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"z7ECaYwQdHr1","colab":{}},"source":["backend.clear_session()\n","\n","#Model 4 (32 batch_size)\n","visible4 = Input(shape=(1000,74))\n","left_conv4 = Conv1D(256, kernel_size=4, strides=2, padding='same')(visible4)\n","right_conv4 = Conv1D(256, kernel_size=4, strides=2, padding='same', activation='sigmoid')(visible4)\n","merge4 = concatenate([left_conv4, right_conv4])\n","gru4 = GRU(128, dropout=0.2, activation=\"sigmoid\",recurrent_activation=\"sigmoid\")(merge4)\n","output4 = Dense(1, activation='sigmoid')(gru4)\n","model4 = Model(inputs=[visible4], outputs=output4)\n","\n","#Model 5 (32 batch_size)\n","model5 = Sequential()  \n","model5.add(Conv1D(256, input_shape=(1000, 74), kernel_size=2, strides=2, padding='same'))  \n","model5.add(AveragePooling1D(pool_size=2, strides=2))  \n","model5.add(GRU(256, dropout=0.3, return_sequences=True, input_shape=(1000, 74)))  \n","model5.add(GRU(128,dropout=0.2,return_sequences=True))  \n","model5.add(Conv1D(256, input_shape=(1000, 74), kernel_size=2, strides=2, padding='same'))  \n","model5.add(AveragePooling1D(pool_size=2, strides=2))  \n","model5.add(GRU(256, dropout=0.2, return_sequences=True, input_shape=(1000, 74)))  \n","model5.add(GRU(128))  \n","model5.add(Dense(1, activation=\"sigmoid\")) \n","\n","#Model 6 (32 batch_size)\n","model6 = Sequential() \n","model6.add(Conv1D(128, input_shape=(1000, 74), activation='relu', kernel_size=4, strides=2, padding='same')) \n","model6.add(GRU(128, dropout=0.2, activation='hard_sigmoid', recurrent_activation='hard_sigmoid', input_shape=(1000, 74))) \n","model6.add(Dense(1, activation=\"sigmoid\"))\n","\n","#Model 7\n","visible7 = Input(shape=(1000,74))\n","left_conv7 = Conv1D(256, kernel_size=4, strides=2, padding='same')(visible7)\n","right_conv = Conv1D(256, kernel_size=4, strides=2, padding='same', activation='sigmoid')(visible7)\n","right_conv7 = GRU(256, dropout=0.2, return_sequences=True, activation=\"sigmoid\",recurrent_activation=\"sigmoid\")(right_conv)\n","merge7 = concatenate([left_conv7, right_conv7])\n","gru7 = GRU(128, dropout=0.2, activation=\"sigmoid\",recurrent_activation=\"sigmoid\")(merge7)\n","output7 = Dense(1, activation='sigmoid')(gru7)\n","model7 = Model(inputs=[visible7], outputs=output7)\n","\n","#Model 8\n","model8 = Sequential()  \n","model8.add(Conv1D(256, input_shape=(1000, 74), kernel_size=2, strides=2, padding='same'))  \n","model8.add(MaxPooling1D(pool_size=2, strides=2))    \n","model8.add(Bidirectional(LSTM(256, input_shape=(1000, 74))))   \n","model8.add(Dense(1, activation=\"sigmoid\")) \n","\n","model4.summary()\n","model5.summary()\n","model6.summary()\n","model7.summary()\n","model8.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pBZBfBvvfvZh","colab_type":"code","colab":{}},"source":["def compile_and_train(model, num_epochs):\n","  # train the model\n","  from keras.callbacks import EarlyStopping,ReduceLROnPlateau,ModelCheckpoint\n","  ReduceLR = ReduceLROnPlateau(factor=0.8,patience=3)\n","  checkpoint = ModelCheckpoint(dirsol+'{val_loss:.4f}.hdf5', monitor='val_loss', \n","                               verbose=1, save_best_only=True, mode='auto')\n","  model.compile(optimizer='adam', loss='binary_crossentropy',metrics=['acc'])\n","  history = model.fit(X_train, y_train, epochs=num_epochs, batch_size=32,\n","                      validation_data=(X_valid, y_valid),callbacks=[ReduceLR,checkpoint])\n","  return history"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eJiDBfRWfwHW","colab_type":"code","colab":{}},"source":["models = [model4,model5,model6,model7,model8]\n","for model in models:\n","  compile_and_train(model, 20)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"o71lmb6GiMsv"},"source":["## Model 9 - 11"]},{"cell_type":"code","metadata":{"id":"HZxc7udHiosh","colab_type":"code","colab":{}},"source":["backend.clear_session()\n","\n","#Model 9 (same as Model 4 but with 128 batch_size)\n","visible9 = Input(shape=(1000,74))\n","left_conv9 = Conv1D(256, kernel_size=4, strides=2, padding='same')(visible9)\n","right_conv9 = Conv1D(256, kernel_size=4, strides=2, padding='same', activation='sigmoid')(visible9)\n","merge9 = concatenate([left_conv9, right_conv9])\n","gru9 = GRU(128, dropout=0.2, activation=\"sigmoid\",recurrent_activation=\"sigmoid\")(merge9)\n","output9 = Dense(1, activation='sigmoid')(gru9)\n","model9 = Model(inputs=[visible9], outputs=output9)\n","\n","#Model 10 (same as Model 5 but with 128 batch_size)\n","model10 = Sequential()  \n","model10.add(Conv1D(256, input_shape=(1000, 74), kernel_size=2, strides=2, padding='same'))  \n","model10.add(AveragePooling1D(pool_size=2, strides=2))  \n","model10.add(GRU(256, dropout=0.3, return_sequences=True, input_shape=(1000, 74)))  \n","model10.add(GRU(128,dropout=0.2,return_sequences=True))  \n","model10.add(Conv1D(256, input_shape=(1000, 74), kernel_size=2, strides=2, padding='same'))  \n","model10.add(AveragePooling1D(pool_size=2, strides=2))  \n","model10.add(GRU(256, dropout=0.2, return_sequences=True, input_shape=(1000, 74)))  \n","model10.add(GRU(128))  \n","model10.add(Dense(1, activation=\"sigmoid\")) \n","\n","#Model 11 (same as Model 6 but with 128 batch_size)\n","model11 = Sequential() \n","model11.add(Conv1D(128, input_shape=(1000, 74), activation='relu', kernel_size=4, strides=2, padding='same')) \n","model11.add(GRU(128, dropout=0.2, activation='hard_sigmoid', recurrent_activation='hard_sigmoid', input_shape=(1000, 74))) \n","model11.add(Dense(1, activation=\"sigmoid\"))\n","\n","model9.summary()\n","model10.summary()\n","model11.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jJEBvO0IgcEI","colab_type":"code","colab":{}},"source":["def compile_and_train(model, num_epochs):\n","  # train the model\n","  from keras.callbacks import EarlyStopping,ReduceLROnPlateau,ModelCheckpoint\n","  ReduceLR = ReduceLROnPlateau(factor=0.8,patience=3)\n","  checkpoint = ModelCheckpoint(dirsol+'{val_loss:.4f}.hdf5', monitor='val_loss', \n","                               verbose=1, save_best_only=True, mode='auto')\n","  model.compile(optimizer='adam', loss='binary_crossentropy',metrics=['acc'])\n","  history = model.fit(X_train, y_train, epochs=num_epochs, batch_size=128,\n","                      validation_data=(X_valid, y_valid),callbacks=[ReduceLR,checkpoint])\n","  return history"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"q8eFS655f9HQ","colab_type":"code","colab":{}},"source":["models = [model9,model10,model11]\n","for model in models:\n","  compile_and_train(model, 20)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"XD8uVYk9nf1Q"},"source":["# Skip Model Training (Optional) "]},{"cell_type":"code","metadata":{"id":"e4q2l8BWn2qb","colab_type":"code","colab":{}},"source":["from keras.models import load_model\n","model1=load_model(dirsol+'model1_2.hdf5')\n","model1.compile(optimizer='adam', loss='binary_crossentropy',metrics=['acc'])\n","model2=load_model(dirsol+'model2_0.hdf5')\n","model2.compile(optimizer='adam', loss='binary_crossentropy',metrics=['acc'])\n","model3=load_model(dirsol+'model2_2.hdf5')\n","model3.compile(optimizer='adam', loss='binary_crossentropy',metrics=['acc'])\n","model4=load_model(dirsol+'model2_11.hdf5')\n","model4.compile(optimizer='adam', loss='binary_crossentropy',metrics=['acc'])\n","model5=load_model(dirsol+'model3.hdf5')\n","model5.compile(optimizer='adam', loss='binary_crossentropy',metrics=['acc'])\n","model6=load_model(dirsol+'model4_1.hdf5')\n","model6.compile(optimizer='adam', loss='binary_crossentropy',metrics=['acc'])\n","model7=load_model(dirsol+'model4.hdf5')\n","model7.compile(optimizer='adam', loss='binary_crossentropy',metrics=['acc'])\n","model8=load_model(dirsol+'modelkiansiong1.hdf5')\n","model8.compile(optimizer='adam', loss='binary_crossentropy',metrics=['acc'])\n","model9=load_model(dirsol+'modelkiansiong2.hdf5')\n","model9.compile(optimizer='adam', loss='binary_crossentropy',metrics=['acc'])\n","model10=load_model(dirsol+'modelandi1.hdf5', compile=False)\n","model10.compile(optimizer='adam', loss='binary_crossentropy',metrics=['acc'])\n","model11=load_model(dirsol+'modelandi2.hdf5', compile=False)\n","model11.compile(optimizer='adam', loss='binary_crossentropy',metrics=['acc'])\n","model12=load_model(dirsol+'model4_2.hdf5')\n","model12.compile(optimizer='adam', loss='binary_crossentropy',metrics=['acc'])\n","model13=load_model(dirsol+'model5.hdf5')\n","model13.compile(optimizer='adam', loss='binary_crossentropy',metrics=['acc'])\n","model14=load_model(dirsol+'modelkiansiong3.hdf5')\n","model14.compile(optimizer='adam', loss='binary_crossentropy',metrics=['acc'])\n","model15=load_model(dirsol+'model5_1.hdf5')\n","model15.compile(optimizer='adam', loss='binary_crossentropy',metrics=['acc'])\n","model16=load_model(dirsol+'model5_2.hdf5')\n","model16.compile(optimizer='adam', loss='binary_crossentropy',metrics=['acc'])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vUNjWbq1BUL6","colab_type":"text"},"source":["# Ensembling and Results Generation "]},{"cell_type":"code","metadata":{"id":"DS5oWw5KlgkB","colab_type":"code","colab":{}},"source":["# read all training sequence for all instances\n","dataPath_test = '/content/kaggle/test/'\n","sequences = list()\n","\n","for i in range(0, len(listdir(dataPath_test))):\n","    file_name = dataPath_test + str(i) + '.npy'\n","    data = np.load(file_name)\n","    df = pd.DataFrame(data=data[:,:], index=None, columns=None)\n","    df = df.drop(df.iloc[:,64:92].head(0).columns, axis=1)\n","    values = df.values\n","    sequences.append(values)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"d7XiPcdgmGGN","colab_type":"code","colab":{}},"source":["# padding the sequence with values from last row for each sequence\n","# since most of the sequence are 1000 length, no need to truncate further after padding\n","\n","to_pad = 1000\n","new_sequences = []\n","for seq in sequences:\n","    len_seq = len(seq)\n","    last_val = [0]*74\n","    n = to_pad - len_seq\n","   \n","    #to_concat = np.repeat(seq[-1], n).reshape(102, n).transpose()\n","    to_concat = np.repeat(last_val, n).reshape(74, n).transpose()\n","    new_seq = np.concatenate([seq, to_concat])\n","    new_sequences.append(new_seq)\n","    \n","final_seq = np.stack(new_sequences)\n","X_test = np.array(final_seq)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tEEoouG93jdT","colab_type":"code","colab":{}},"source":["# test the model\n","models = [model1, model2, model3, model4, model5, model6, \n","          model7, model8, model9, model10, model11]\n","Result=np.zeros((X_test.shape[0],1))\n","for model in models:\n","  Result = np.add(Result,model.predict(X_test, batch_size=32))\n","Result = Result/11"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tTl3QK-2F4Wu","colab_type":"code","outputId":"3ade62c3-6b16-4fa9-b337-4ea1dfe3f61e","executionInfo":{"status":"ok","timestamp":1573203493500,"user_tz":-480,"elapsed":1557265,"user":{"displayName":"Ghozali Hadi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDtBXh1HpepQnY8r5dcNsH1XRVe5hg2_CDe31fLYQ=s64","userId":"15306670381666841801"}},"colab":{"base_uri":"https://localhost:8080/","height":156}},"source":["print(Result.shape)\n","print(Result)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(6051, 1)\n","[[9.99744967e-01]\n"," [9.87761583e-01]\n"," [1.26498379e-03]\n"," ...\n"," [6.31005217e-04]\n"," [6.73464430e-01]\n"," [6.86415867e-04]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2EuZLxAOyrrO","colab_type":"code","outputId":"ed91628f-5614-4af9-ff19-d3c6adcff4ae","executionInfo":{"status":"ok","timestamp":1573203493501,"user_tz":-480,"elapsed":1542029,"user":{"displayName":"Ghozali Hadi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDtBXh1HpepQnY8r5dcNsH1XRVe5hg2_CDe31fLYQ=s64","userId":"15306670381666841801"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","pd.DataFrame(Result, columns=['Predicted']).to_csv('/content/drive/solution.csv',index_label='Id')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]}]}